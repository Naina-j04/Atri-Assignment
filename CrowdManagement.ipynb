{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqWATBrpOHz8o5iheCIQcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naina-j04/Atri-Assignment/blob/main/CrowdManagement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbijmSXOVU2A",
        "outputId": "2642833f-fd8d-4d7c-d563-af4c15df7846"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.204-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.204-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.204 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGiZkgddVIUL",
        "outputId": "2a78b97b-12db-4229-91ed-38639bf433a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 14 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 6.8ms\n",
            "Speed: 3.7ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 8.4ms\n",
            "Speed: 3.7ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 14 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 14 - Safe\n",
            "\n",
            "0: 384x640 14 persons, 9.0ms\n",
            "Speed: 4.2ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 14 - Safe\n",
            "\n",
            "0: 384x640 14 persons, 9.2ms\n",
            "Speed: 3.8ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 14 - Safe\n",
            "\n",
            "0: 384x640 17 persons, 9.0ms\n",
            "Speed: 4.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 6.4ms\n",
            "Speed: 3.3ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 6.6ms\n",
            "Speed: 2.8ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 9.9ms\n",
            "Speed: 4.2ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 8.6ms\n",
            "Speed: 4.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 7.0ms\n",
            "Speed: 3.5ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 9.1ms\n",
            "Speed: 4.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 9.0ms\n",
            "Speed: 4.8ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.6ms\n",
            "Speed: 5.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 handbag, 8.0ms\n",
            "Speed: 3.6ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 handbag, 16.2ms\n",
            "Speed: 3.7ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 1 handbag, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 1 handbag, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 6.5ms\n",
            "Speed: 3.4ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 handbag, 11.1ms\n",
            "Speed: 5.3ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 6.3ms\n",
            "Speed: 3.1ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 9.5ms\n",
            "Speed: 5.0ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 8.9ms\n",
            "Speed: 4.5ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 6.6ms\n",
            "Speed: 5.0ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 8.6ms\n",
            "Speed: 3.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 6.8ms\n",
            "Speed: 2.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 13.0ms\n",
            "Speed: 4.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 8.9ms\n",
            "Speed: 4.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 10.4ms\n",
            "Speed: 5.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 6.8ms\n",
            "Speed: 3.3ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.4ms\n",
            "Speed: 4.5ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 6.3ms\n",
            "Speed: 3.4ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.9ms\n",
            "Speed: 5.2ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 handbag, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 6.5ms\n",
            "Speed: 3.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 9.5ms\n",
            "Speed: 5.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 6.7ms\n",
            "Speed: 3.5ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.9ms\n",
            "Speed: 4.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.7ms\n",
            "Speed: 4.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.3ms\n",
            "Speed: 4.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 8.7ms\n",
            "Speed: 3.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 6.5ms\n",
            "Speed: 3.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 9.6ms\n",
            "Speed: 4.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 8.3ms\n",
            "Speed: 3.8ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 6.6ms\n",
            "Speed: 2.6ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.2ms\n",
            "Speed: 3.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 6.4ms\n",
            "Speed: 3.1ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 1 handbag, 11.5ms\n",
            "Speed: 5.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 8.0ms\n",
            "Speed: 3.7ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 7.1ms\n",
            "Speed: 3.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 7.5ms\n",
            "Speed: 4.0ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.6ms\n",
            "Speed: 3.8ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.6ms\n",
            "Speed: 4.3ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.5ms\n",
            "Speed: 3.7ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 6.6ms\n",
            "Speed: 3.3ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 2 handbags, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 11.8ms\n",
            "Speed: 5.0ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.4ms\n",
            "Speed: 4.0ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 6.6ms\n",
            "Speed: 3.3ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 2 handbags, 8.8ms\n",
            "Speed: 4.4ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 9.5ms\n",
            "Speed: 4.3ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 6.5ms\n",
            "Speed: 3.5ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.7ms\n",
            "Speed: 4.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 9.3ms\n",
            "Speed: 4.1ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.5ms\n",
            "Speed: 4.0ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7.5ms\n",
            "Speed: 4.7ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.7ms\n",
            "Speed: 4.6ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 9.9ms\n",
            "Speed: 4.3ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 9.5ms\n",
            "Speed: 4.3ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 15 - Safe\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 1 handbag, 6.4ms\n",
            "Speed: 3.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 4 handbags, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 24.1ms\n",
            "Speed: 6.2ms preprocess, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 handbag, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 2 stop signs, 2 handbags, 9.0ms\n",
            "Speed: 4.0ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 8.6ms\n",
            "Speed: 5.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 7.3ms\n",
            "Speed: 3.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 2 handbags, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 handbag, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 6.5ms\n",
            "Speed: 3.5ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 12.9ms\n",
            "Speed: 4.1ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 2 handbags, 6.6ms\n",
            "Speed: 3.5ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.9ms\n",
            "Speed: 4.4ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 handbag, 9.3ms\n",
            "Speed: 4.6ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 handbag, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 2 handbags, 7.2ms\n",
            "Speed: 3.6ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 handbag, 20.3ms\n",
            "Speed: 6.2ms preprocess, 20.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 7.4ms\n",
            "Speed: 4.2ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 9.8ms\n",
            "Speed: 5.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.2ms\n",
            "Speed: 4.9ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 6.5ms\n",
            "Speed: 3.4ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 9.4ms\n",
            "Speed: 4.3ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 9.4ms\n",
            "Speed: 6.3ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 6.5ms\n",
            "Speed: 3.6ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 9.1ms\n",
            "Speed: 4.4ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 9.5ms\n",
            "Speed: 7.7ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 12.9ms\n",
            "Speed: 6.2ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 19 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 18.1ms\n",
            "Speed: 7.4ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 13.4ms\n",
            "Speed: 9.5ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 12.9ms\n",
            "Speed: 3.6ms preprocess, 12.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 12.5ms\n",
            "Speed: 3.8ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 24.0ms\n",
            "Speed: 5.0ms preprocess, 24.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.0ms\n",
            "Speed: 3.6ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 10.9ms\n",
            "Speed: 6.3ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 19 persons, 16.1ms\n",
            "Speed: 7.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 19 - Overcrowded\n",
            "\n",
            "0: 384x640 19 persons, 17.6ms\n",
            "Speed: 6.7ms preprocess, 17.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 19 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 12.8ms\n",
            "Speed: 8.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 13.9ms\n",
            "Speed: 7.1ms preprocess, 13.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 17.0ms\n",
            "Speed: 8.0ms preprocess, 17.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 19 persons, 16.8ms\n",
            "Speed: 6.7ms preprocess, 16.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 19 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 17.1ms\n",
            "Speed: 7.8ms preprocess, 17.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 15.7ms\n",
            "Speed: 8.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 15.7ms\n",
            "Speed: 7.0ms preprocess, 15.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 17.8ms\n",
            "Speed: 8.3ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 11.9ms\n",
            "Speed: 5.3ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 15.1ms\n",
            "Speed: 4.2ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 15.7ms\n",
            "Speed: 7.1ms preprocess, 15.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.6ms\n",
            "Speed: 5.1ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 14.1ms\n",
            "Speed: 5.1ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 12.5ms\n",
            "Speed: 4.0ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 26.0ms\n",
            "Speed: 6.5ms preprocess, 26.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 20.8ms\n",
            "Speed: 8.9ms preprocess, 20.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 8.7ms\n",
            "Speed: 4.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 6.4ms\n",
            "Speed: 3.5ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 9.3ms\n",
            "Speed: 4.7ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 9.4ms\n",
            "Speed: 4.7ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 8.6ms\n",
            "Speed: 4.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 7.5ms\n",
            "Speed: 3.5ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 12.6ms\n",
            "Speed: 4.3ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.8ms\n",
            "Speed: 5.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 7.5ms\n",
            "Speed: 3.6ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 19 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 6.4ms\n",
            "Speed: 3.4ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 8.6ms\n",
            "Speed: 5.4ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 6.3ms\n",
            "Speed: 3.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.1ms\n",
            "Speed: 5.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 6.6ms\n",
            "Speed: 3.3ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 8.8ms\n",
            "Speed: 4.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 9.0ms\n",
            "Speed: 4.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.3ms\n",
            "Speed: 3.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 6.6ms\n",
            "Speed: 3.5ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 13.5ms\n",
            "Speed: 3.3ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 6.8ms\n",
            "Speed: 3.4ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 8.3ms\n",
            "Speed: 5.1ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 6.4ms\n",
            "Speed: 3.4ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.9ms\n",
            "Speed: 3.6ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 7.7ms\n",
            "Speed: 3.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 8.8ms\n",
            "Speed: 4.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 8.5ms\n",
            "Speed: 5.5ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 6.5ms\n",
            "Speed: 3.3ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 9.1ms\n",
            "Speed: 4.5ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 6.9ms\n",
            "Speed: 3.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.7ms\n",
            "Speed: 4.5ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.6ms\n",
            "Speed: 3.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 6.6ms\n",
            "Speed: 3.6ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.9ms\n",
            "Speed: 5.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 backpack, 10.8ms\n",
            "Speed: 4.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 backpack, 7.0ms\n",
            "Speed: 3.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 9.9ms\n",
            "Speed: 5.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.6ms\n",
            "Speed: 4.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 12.5ms\n",
            "Speed: 4.0ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 11.9ms\n",
            "Speed: 6.2ms preprocess, 11.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 10.5ms\n",
            "Speed: 4.5ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 7.9ms\n",
            "Speed: 4.2ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.0ms\n",
            "Speed: 4.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.1ms\n",
            "Speed: 4.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.6ms\n",
            "Speed: 7.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 6.5ms\n",
            "Speed: 4.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 9.5ms\n",
            "Speed: 5.4ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 8.8ms\n",
            "Speed: 5.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 16 persons, 9.0ms\n",
            "Speed: 5.1ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 16 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 18 - Overcrowded\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 6.0ms\n",
            "Speed: 3.1ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "People: 17 - Overcrowded\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "cap = cv2.VideoCapture(\"people.mp4\")\n",
        "\n",
        "max_capacity = 15\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    results = model(frame)[0]\n",
        "    count = sum(1 for box in results.boxes if int(box.cls) == 0)\n",
        "    print(f\"People: {count} - {'Overcrowded' if count > max_capacity else 'Safe'}\")\n",
        "cap.release()\n"
      ]
    }
  ]
}