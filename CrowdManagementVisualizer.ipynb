{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naina-j04/Atri-Assignment/blob/main/CrowdManagementVisualizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeA6QYfEbsOD",
        "outputId": "3d643c64-8902-4ceb-caa9-56c3a1b0812a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.209-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.209-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.209 ultralytics-thop-2.0.17\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSjDmTN-cBb1",
        "outputId": "a261e8f8-f189-4298-8607-c0077cd75d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 99.8MB/s 0.1s\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 76.4ms\n",
            "Speed: 15.7ms preprocess, 76.4ms inference, 356.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 9.4ms\n",
            "Speed: 5.1ms preprocess, 9.4ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 12.7ms\n",
            "Speed: 4.4ms preprocess, 12.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 10.4ms\n",
            "Speed: 4.2ms preprocess, 10.4ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 17.1ms\n",
            "Speed: 5.3ms preprocess, 17.1ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 9.2ms\n",
            "Speed: 5.0ms preprocess, 9.2ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 12.2ms\n",
            "Speed: 6.4ms preprocess, 12.2ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 13.1ms\n",
            "Speed: 5.7ms preprocess, 13.1ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 10.5ms\n",
            "Speed: 4.2ms preprocess, 10.5ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 9.7ms\n",
            "Speed: 4.8ms preprocess, 9.7ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 8.6ms\n",
            "Speed: 3.9ms preprocess, 8.6ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 12.8ms\n",
            "Speed: 5.6ms preprocess, 12.8ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.5ms\n",
            "Speed: 6.3ms preprocess, 9.5ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 10.0ms\n",
            "Speed: 4.3ms preprocess, 10.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.6ms\n",
            "Speed: 3.9ms preprocess, 9.6ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 handbag, 8.8ms\n",
            "Speed: 4.1ms preprocess, 8.8ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 handbag, 10.2ms\n",
            "Speed: 4.5ms preprocess, 10.2ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 1 handbag, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 1 handbag, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 9.8ms\n",
            "Speed: 5.3ms preprocess, 9.8ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 handbag, 9.6ms\n",
            "Speed: 6.2ms preprocess, 9.6ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.5ms\n",
            "Speed: 4.2ms preprocess, 8.5ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.8ms\n",
            "Speed: 4.9ms preprocess, 8.8ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.7ms\n",
            "Speed: 4.9ms preprocess, 8.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.5ms\n",
            "Speed: 4.5ms preprocess, 8.5ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.5ms\n",
            "Speed: 4.0ms preprocess, 8.5ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 48.9ms\n",
            "Speed: 11.2ms preprocess, 48.9ms inference, 38.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 9.4ms\n",
            "Speed: 4.7ms preprocess, 9.4ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 8.5ms\n",
            "Speed: 4.7ms preprocess, 8.5ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 8.7ms\n",
            "Speed: 4.7ms preprocess, 8.7ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 34.7ms\n",
            "Speed: 3.2ms preprocess, 34.7ms inference, 35.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 9.0ms\n",
            "Speed: 4.9ms preprocess, 9.0ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 17.9ms\n",
            "Speed: 9.3ms preprocess, 17.9ms inference, 20.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 9.8ms\n",
            "Speed: 6.2ms preprocess, 9.8ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.6ms\n",
            "Speed: 6.2ms preprocess, 8.6ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 19.5ms\n",
            "Speed: 6.5ms preprocess, 19.5ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 22.7ms\n",
            "Speed: 6.7ms preprocess, 22.7ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 15.0ms\n",
            "Speed: 6.3ms preprocess, 15.0ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 14.3ms\n",
            "Speed: 7.7ms preprocess, 14.3ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.2ms\n",
            "Speed: 5.6ms preprocess, 8.2ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 19.7ms\n",
            "Speed: 4.2ms preprocess, 19.7ms inference, 20.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 14.8ms\n",
            "Speed: 7.0ms preprocess, 14.8ms inference, 20.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 15.6ms\n",
            "Speed: 6.2ms preprocess, 15.6ms inference, 20.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 16.8ms\n",
            "Speed: 6.2ms preprocess, 16.8ms inference, 25.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 handbag, 24.0ms\n",
            "Speed: 7.9ms preprocess, 24.0ms inference, 22.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 20.2ms\n",
            "Speed: 5.3ms preprocess, 20.2ms inference, 26.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 10.3ms\n",
            "Speed: 4.3ms preprocess, 10.3ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.7ms\n",
            "Speed: 5.1ms preprocess, 8.7ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.4ms\n",
            "Speed: 3.8ms preprocess, 8.4ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 10.4ms\n",
            "Speed: 5.5ms preprocess, 10.4ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 handbags, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 13.1ms\n",
            "Speed: 5.6ms preprocess, 13.1ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 handbags, 9.4ms\n",
            "Speed: 5.3ms preprocess, 9.4ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 8.5ms\n",
            "Speed: 4.2ms preprocess, 8.5ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 10.9ms\n",
            "Speed: 6.1ms preprocess, 10.9ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 9.4ms\n",
            "Speed: 4.3ms preprocess, 9.4ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 1 handbag, 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 handbag, 8.0ms\n",
            "Speed: 4.4ms preprocess, 8.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.6ms\n",
            "Speed: 4.3ms preprocess, 8.6ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.6ms\n",
            "Speed: 4.4ms preprocess, 8.6ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.6ms\n",
            "Speed: 4.4ms preprocess, 8.6ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 11.1ms\n",
            "Speed: 5.1ms preprocess, 11.1ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 10.9ms\n",
            "Speed: 4.8ms preprocess, 10.9ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.7ms\n",
            "Speed: 4.7ms preprocess, 8.7ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.8ms\n",
            "Speed: 4.3ms preprocess, 8.8ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 9.4ms\n",
            "Speed: 5.3ms preprocess, 9.4ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.9ms\n",
            "Speed: 5.2ms preprocess, 8.9ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.4ms\n",
            "Speed: 4.8ms preprocess, 8.4ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 9.2ms\n",
            "Speed: 5.1ms preprocess, 9.2ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 2 handbags, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.5ms\n",
            "Speed: 5.0ms preprocess, 8.5ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 9.1ms\n",
            "Speed: 5.8ms preprocess, 9.1ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 handbags, 9.8ms\n",
            "Speed: 5.2ms preprocess, 9.8ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.6ms\n",
            "Speed: 4.9ms preprocess, 8.6ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.9ms\n",
            "Speed: 4.7ms preprocess, 8.9ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 8.7ms\n",
            "Speed: 4.8ms preprocess, 8.7ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.5ms\n",
            "Speed: 6.0ms preprocess, 8.5ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.6ms\n",
            "Speed: 5.8ms preprocess, 8.6ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.4ms\n",
            "Speed: 4.7ms preprocess, 8.4ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 8.8ms\n",
            "Speed: 5.0ms preprocess, 8.8ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.5ms\n",
            "Speed: 4.8ms preprocess, 8.5ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 8.9ms\n",
            "Speed: 4.1ms preprocess, 8.9ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 8.5ms\n",
            "Speed: 4.2ms preprocess, 8.5ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 1 handbag, 8.7ms\n",
            "Speed: 4.2ms preprocess, 8.7ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 8.5ms\n",
            "Speed: 4.3ms preprocess, 8.5ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 handbags, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 10.2ms\n",
            "Speed: 5.4ms preprocess, 10.2ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 handbag, 8.8ms\n",
            "Speed: 4.5ms preprocess, 8.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 2 stop signs, 2 handbags, 9.7ms\n",
            "Speed: 4.5ms preprocess, 9.7ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 8.4ms\n",
            "Speed: 4.3ms preprocess, 8.4ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 9.8ms\n",
            "Speed: 4.2ms preprocess, 9.8ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 8.7ms\n",
            "Speed: 4.7ms preprocess, 8.7ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 2 handbags, 8.5ms\n",
            "Speed: 4.4ms preprocess, 8.5ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 handbag, 8.5ms\n",
            "Speed: 4.7ms preprocess, 8.5ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.9ms\n",
            "Speed: 4.2ms preprocess, 8.9ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.4ms\n",
            "Speed: 4.0ms preprocess, 8.4ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.6ms\n",
            "Speed: 3.8ms preprocess, 8.6ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 2 handbags, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 10.7ms\n",
            "Speed: 4.2ms preprocess, 10.7ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 handbag, 8.9ms\n",
            "Speed: 5.0ms preprocess, 8.9ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 handbag, 9.8ms\n",
            "Speed: 4.8ms preprocess, 9.8ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 2 handbags, 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 8.7ms\n",
            "Speed: 5.1ms preprocess, 8.7ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 handbag, 13.2ms\n",
            "Speed: 4.1ms preprocess, 13.2ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 12.9ms\n",
            "Speed: 3.6ms preprocess, 12.9ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 19.6ms\n",
            "Speed: 5.2ms preprocess, 19.6ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 20.6ms\n",
            "Speed: 9.5ms preprocess, 20.6ms inference, 27.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 18.1ms\n",
            "Speed: 8.6ms preprocess, 18.1ms inference, 23.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 16.0ms\n",
            "Speed: 8.2ms preprocess, 16.0ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 19.1ms\n",
            "Speed: 7.4ms preprocess, 19.1ms inference, 25.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 14.5ms\n",
            "Speed: 7.0ms preprocess, 14.5ms inference, 20.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 11.7ms\n",
            "Speed: 5.0ms preprocess, 11.7ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 22.3ms\n",
            "Speed: 4.3ms preprocess, 22.3ms inference, 22.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 24.7ms\n",
            "Speed: 7.0ms preprocess, 24.7ms inference, 19.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 9.1ms\n",
            "Speed: 6.4ms preprocess, 9.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.0ms\n",
            "Speed: 7.1ms preprocess, 9.0ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.2ms\n",
            "Speed: 5.6ms preprocess, 9.2ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.1ms\n",
            "Speed: 5.6ms preprocess, 9.1ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 10.9ms\n",
            "Speed: 5.2ms preprocess, 10.9ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 8.9ms\n",
            "Speed: 4.6ms preprocess, 8.9ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.4ms\n",
            "Speed: 5.1ms preprocess, 8.4ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.6ms\n",
            "Speed: 5.5ms preprocess, 8.6ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 11.6ms\n",
            "Speed: 4.9ms preprocess, 11.6ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 8.7ms\n",
            "Speed: 5.9ms preprocess, 8.7ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 9.6ms\n",
            "Speed: 4.3ms preprocess, 9.6ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.4ms\n",
            "Speed: 3.8ms preprocess, 8.4ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.2ms\n",
            "Speed: 3.9ms preprocess, 9.2ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 10.2ms\n",
            "Speed: 3.8ms preprocess, 10.2ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 9.6ms\n",
            "Speed: 4.3ms preprocess, 9.6ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 handbag, 9.1ms\n",
            "Speed: 3.9ms preprocess, 9.1ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.9ms\n",
            "Speed: 5.9ms preprocess, 8.9ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.8ms\n",
            "Speed: 6.1ms preprocess, 8.8ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 16.1ms\n",
            "Speed: 5.8ms preprocess, 16.1ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 15.7ms\n",
            "Speed: 8.0ms preprocess, 15.7ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.8ms\n",
            "Speed: 5.2ms preprocess, 9.8ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 8.7ms\n",
            "Speed: 4.0ms preprocess, 8.7ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.4ms\n",
            "Speed: 4.9ms preprocess, 9.4ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.2ms\n",
            "Speed: 6.6ms preprocess, 9.2ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.1ms\n",
            "Speed: 4.5ms preprocess, 9.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 9.9ms\n",
            "Speed: 5.5ms preprocess, 9.9ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 10.5ms\n",
            "Speed: 6.8ms preprocess, 10.5ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 8.9ms\n",
            "Speed: 5.7ms preprocess, 8.9ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 8.7ms\n",
            "Speed: 4.7ms preprocess, 8.7ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.9ms\n",
            "Speed: 6.0ms preprocess, 8.9ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 8.9ms\n",
            "Speed: 5.0ms preprocess, 8.9ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 8.9ms\n",
            "Speed: 4.4ms preprocess, 8.9ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 8.8ms\n",
            "Speed: 4.3ms preprocess, 8.8ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 8.6ms\n",
            "Speed: 4.4ms preprocess, 8.6ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 9.2ms\n",
            "Speed: 4.7ms preprocess, 9.2ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.8ms\n",
            "Speed: 4.2ms preprocess, 8.8ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.9ms\n",
            "Speed: 4.7ms preprocess, 8.9ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 13.8ms\n",
            "Speed: 10.0ms preprocess, 13.8ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 8.8ms\n",
            "Speed: 5.0ms preprocess, 8.8ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.2ms\n",
            "Speed: 5.4ms preprocess, 9.2ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 18.5ms\n",
            "Speed: 10.6ms preprocess, 18.5ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 backpack, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 backpack, 18.0ms\n",
            "Speed: 5.2ms preprocess, 18.0ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 20.7ms\n",
            "Speed: 4.4ms preprocess, 20.7ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 15.9ms\n",
            "Speed: 8.6ms preprocess, 15.9ms inference, 20.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 15.4ms\n",
            "Speed: 6.3ms preprocess, 15.4ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 20.7ms\n",
            "Speed: 7.3ms preprocess, 20.7ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 15.6ms\n",
            "Speed: 8.4ms preprocess, 15.6ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 17.8ms\n",
            "Speed: 8.1ms preprocess, 17.8ms inference, 22.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 16.1ms\n",
            "Speed: 6.8ms preprocess, 16.1ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 10.7ms\n",
            "Speed: 7.0ms preprocess, 10.7ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 22.6ms\n",
            "Speed: 9.4ms preprocess, 22.6ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 17.9ms\n",
            "Speed: 7.0ms preprocess, 17.9ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 10.5ms\n",
            "Speed: 5.1ms preprocess, 10.5ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.7ms\n",
            "Speed: 6.4ms preprocess, 8.7ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.8ms\n",
            "Speed: 5.5ms preprocess, 8.8ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.8ms\n",
            "Speed: 4.5ms preprocess, 8.8ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.0ms\n",
            "Speed: 4.5ms preprocess, 9.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 6.6ms\n",
            "Speed: 3.0ms preprocess, 6.6ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 7.9ms\n",
            "Speed: 5.0ms preprocess, 7.9ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 7.9ms\n",
            "Speed: 3.5ms preprocess, 7.9ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing complete\n",
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "cap = cv2.VideoCapture(\"people.mp4\")\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('crowd.mp4', fourcc,\n",
        "                      cap.get(cv2.CAP_PROP_FPS),\n",
        "                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                       int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "\n",
        "max_capacity = 15\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame)[0]\n",
        "    count = sum(1 for box in results.boxes if int(box.cls) == 0)\n",
        "\n",
        "    for box in results.boxes:\n",
        "        if int(box.cls) == 0:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
        "            color = (0, 0, 255) if count > max_capacity else (0, 255, 0)\n",
        "            label = \"Overcrowded\" if count > max_capacity else \"Safe\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "\n",
        "    cv2.putText(frame, f\"People: {count}\", (20, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Processing complete\")\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('crowd.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=800 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNuhDjFc1jIzJyFN2DpHoEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}