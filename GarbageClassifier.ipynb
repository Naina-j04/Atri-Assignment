{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1g7SS6DF4ZuRKtoHsdbeQ3XfIQjcBd_Cm",
      "authorship_tag": "ABX9TyPJIJZH57ea7axGI0AJ2n/i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naina-j04/Garbage_classifier/blob/main/GarbageClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TDOOcPLTCM6x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRs0MnTSD2rc",
        "outputId": "c79b59c4-afe6-4c93-ede7-8c0930bc996b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pointing to dataset\n",
        "data_dir  = '/content/drive/MyDrive/Garbage_classification/Data'\n",
        "\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ORVPfMbCfwS",
        "outputId": "eb15caee-5e09-4473-ccca-c44e07d84398"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plastic', 'trash', 'paper', 'glass', 'metal', 'cardboard', 'garbage.pth', 'Models', '.ipynb_checkpoints']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resizing and normalizing the dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transformations = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform = transformations)"
      ],
      "metadata": {
        "id": "Rn2Q0WW2EXTd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WASsrWTUmxpx",
        "outputId": "cf5fddb7-3242-4d70-fbaa-0d83ce835849"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2527"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,val_data,test_data=random_split(dataset,[1616,405,506])\n",
        "len(train_data),len(val_data),len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4FX9gWwnXRr",
        "outputId": "6e57619f-bcae-432d-fd6c-79880294142c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1616, 405, 506)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GarbageCNN(nn.Module):\n",
        "  def __init__(self,classes=6):\n",
        "    super (GarbageCNN,self).__init__()\n",
        "\n",
        "    self.c1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,padding=1)\n",
        "    self.c2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,padding=1)\n",
        "    self.c3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1)\n",
        "    self.c4=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1)\n",
        "    self.c5=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1)\n",
        "\n",
        "    self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.fc = nn.Linear(256 * 7 * 7, classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.pool(F.relu(self.c1(x)))\n",
        "    x=self.pool(F.relu(self.c2(x)))\n",
        "    x=self.pool(F.relu(self.c3(x)))\n",
        "    x=self.pool(F.relu(self.c4(x)))\n",
        "    x=self.pool(F.relu(self.c5(x)))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "garbage=GarbageCNN()\n"
      ],
      "metadata": {
        "id": "9jCzDDS2oMuI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader=DataLoader(train_data,batch_size=32,shuffle=True)\n",
        "val_loader=DataLoader(val_data,batch_size=32,shuffle=False)\n",
        "test_loader=DataLoader(test_data,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "hHgEtbGPuHpL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "#starting the training\n",
        "classes=6\n",
        "model=GarbageCNN(classes)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001,)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g55FGaOvAtL",
        "outputId": "bc371032-157a-470c-eb63-1c93d841b741"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "print(\"Starting Training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, '\n",
        "          f'Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "print('Finished Training.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEQ5kZ0D9Th3",
        "outputId": "90768afc-5499-4fec-bf59-7910a49443be"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "Epoch [1/20], Training Loss: 1.6028, Validation Loss: 1.4459, Validation Accuracy: 39.26%\n",
            "Epoch [2/20], Training Loss: 1.3236, Validation Loss: 1.2293, Validation Accuracy: 52.59%\n",
            "Epoch [3/20], Training Loss: 1.1350, Validation Loss: 1.1784, Validation Accuracy: 56.30%\n",
            "Epoch [4/20], Training Loss: 1.0486, Validation Loss: 0.9972, Validation Accuracy: 61.73%\n",
            "Epoch [5/20], Training Loss: 0.9315, Validation Loss: 0.9922, Validation Accuracy: 64.69%\n",
            "Epoch [6/20], Training Loss: 0.8350, Validation Loss: 1.0390, Validation Accuracy: 61.23%\n",
            "Epoch [7/20], Training Loss: 0.7677, Validation Loss: 0.9685, Validation Accuracy: 64.69%\n",
            "Epoch [8/20], Training Loss: 0.7103, Validation Loss: 0.9857, Validation Accuracy: 65.93%\n",
            "Epoch [9/20], Training Loss: 0.5775, Validation Loss: 0.9572, Validation Accuracy: 69.63%\n",
            "Epoch [10/20], Training Loss: 0.5144, Validation Loss: 0.9002, Validation Accuracy: 68.89%\n",
            "Epoch [11/20], Training Loss: 0.4177, Validation Loss: 1.0215, Validation Accuracy: 68.40%\n",
            "Epoch [12/20], Training Loss: 0.3134, Validation Loss: 1.2153, Validation Accuracy: 65.68%\n",
            "Epoch [13/20], Training Loss: 0.2185, Validation Loss: 1.3063, Validation Accuracy: 68.40%\n",
            "Epoch [14/20], Training Loss: 0.1870, Validation Loss: 1.2839, Validation Accuracy: 69.63%\n",
            "Epoch [15/20], Training Loss: 0.1957, Validation Loss: 1.4376, Validation Accuracy: 63.95%\n",
            "Epoch [16/20], Training Loss: 0.1721, Validation Loss: 1.4227, Validation Accuracy: 70.37%\n",
            "Epoch [17/20], Training Loss: 0.0836, Validation Loss: 1.7852, Validation Accuracy: 70.62%\n",
            "Epoch [18/20], Training Loss: 0.0734, Validation Loss: 1.8258, Validation Accuracy: 70.12%\n",
            "Epoch [19/20], Training Loss: 0.0754, Validation Loss: 1.9846, Validation Accuracy: 68.15%\n",
            "Epoch [20/20], Training Loss: 0.0568, Validation Loss: 1.6559, Validation Accuracy: 71.11%\n",
            "Finished Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL TEST EVALUATION\n",
        "print('Starting Final Evaluation on Test Set...')\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        test_loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Final Test Loss: {avg_test_loss:.4f}, Final Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXKXmVPc_hRU",
        "outputId": "2fc4faab-855f-4bde-9850-ee40392de562"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Final Evaluation on Test Set...\n",
            "Final Test Loss: 1.4883, Final Test Accuracy: 72.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Garbage_classification/Data/bettermodel.pth'\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "fZJ5wXMoAOFc"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}